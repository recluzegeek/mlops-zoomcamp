{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f83b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-09 02:01:03--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.155.128.46, 18.155.128.6, 18.155.128.187, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.155.128.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47748012 (46M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2023-02.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  45.54M  6.03MB/s    in 8.3s    \n",
      "\n",
      "2025-05-09 02:01:12 (5.46 MB/s) - ‘yellow_tripdata_2023-02.parquet’ saved [47748012/47748012]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05267c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Set pandas display option to avoid scientific notation\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cc65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b802e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \n",
    "    df = pd.read_parquet(file, engine = 'fastparquet')\n",
    "    \n",
    "    # computing duration\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    \n",
    "    # getting standard deviation\n",
    "    print(df.duration.describe())\n",
    "    \n",
    "    # dropping outliers\n",
    "    df = df[(df.duration >=1) & (df.duration <= 60)]\n",
    "    \n",
    "    # cast pickup and dropoff ids into strings - otherwise it'll label-encode them\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9dcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file, categorical):\n",
    "    # Read the data from parquet file\n",
    "    df = pd.read_parquet(file, engine='fastparquet')\n",
    "    \n",
    "    # Ensure datetime columns are in correct format\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    \n",
    "    # Compute duration in minutes using vectorized operations\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    \n",
    "    # Print the duration statistics\n",
    "    print(df['duration'].describe())\n",
    "    \n",
    "    # Dropping outliers by filtering duration between 1 and 60 minutes\n",
    "    print(((df.duration >= 1) & (df.duration <= 60)).mean())\n",
    "    df = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "    \n",
    "    # Cast categorical columns into strings\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   3066766.00\n",
      "mean         15.67\n",
      "std          42.59\n",
      "min         -29.20\n",
      "25%           7.12\n",
      "50%          11.52\n",
      "75%          18.30\n",
      "max       10029.18\n",
      "Name: duration, dtype: float64\n",
      "0.9812202822125979\n",
      "count   2913955.00\n",
      "mean         16.02\n",
      "std          42.84\n",
      "min         -43.62\n",
      "25%           7.25\n",
      "50%          11.80\n",
      "75%          18.77\n",
      "max        7053.62\n",
      "Name: duration, dtype: float64\n",
      "0.9800944077722545\n"
     ]
    }
   ],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "df_train = read_data('yellow_tripdata_2023-01.parquet', categorical)\n",
    "df_val = read_data('yellow_tripdata_2023-02.parquet', categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f057669",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38f6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# feature matrix\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts) # feature matrix - training input\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts) # feature matrix - validation input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4e47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "\n",
    "y_train = df_train[target].values # target values for training data\n",
    "y_val = df_val[target].values # target values for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a599f4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8bd984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.48793351650686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_val)\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76512b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(y_train.iloc[:10], label='target')\n",
    "sns.distplot(y_pred.iloc[:10], label='prediction')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
